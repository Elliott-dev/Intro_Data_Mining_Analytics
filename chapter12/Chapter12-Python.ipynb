{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Chapter 12: Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Data mining is the process of analyzing data to discover patterns and relationships. If you are working with sales data, for example, it makes sense that you would analyze data to determine facts such as:\n",
    "\n",
    "    •\tWhich customer purchased the most products?\n",
    "    •\tWhich customer purchased the least?\n",
    "    •\tWhat was the average sales per customer order?\n",
    "    •\tWhat was the average number of days between orders?\n",
    "    •\tWhat customers have not yet ordered the new product?\n",
    "    •\tAnd so on.\n",
    "\n",
    "Using data in this way to describe past events is descriptive analytics. As you might imagine, being able to analyze data to determine such historical facts is very important and very valuable to businesses. To perform descriptive analytics, you can use statistical tools to generate metrics, you can use visualization tools to chart data, you can use clustering to group data, and more.\n",
    "\n",
    "This notebook, however, is about using data to predict future events—predictive analytics. Companies, today, use predictive analytics for a wide range of applications:\n",
    "\n",
    "    •\tEstimate the revenue opportunity associated with an upcoming product sale.\n",
    "    •\tPredict the length of time machines will run without failing.\n",
    "    •\tDetermine the loan amount to offer a customer.\n",
    "    •\tWhich customers are likely to become long-term customers?\n",
    "    •\tFor what price will a sea-side home in Seattle sell?\n",
    "    •\tAnd more.\n",
    "\n",
    "\n",
    "Using supervised learning (training with labelled datasets to learn links between inputs and outputs), you can predict in which class (category) an object should reside given predictor variables. Classification works with discrete categories, meaning data that has finite values, such as the type of a car, breed of a dog, color of hair, number of students (you can’t have a fractional student), and so on. In contrast, continuous values have an infinite set of values, such as a company’s projected revenue, the average basketball player’s height, and the range of temperatures in Phoenix.  \n",
    "\n",
    "This notebook focuses on predicting continuous values using a technique called regression, the goal of which is to produce an equation which you can then use to predict results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Some of the scripts presented in this notebook use several Python libraries which have been pre-installed for you. If you had been required to install these libaries on your own, you would issue the following commands:\n",
    "\n",
    "```python\n",
    "! pip install --user pandas\n",
    "! pip install --user numpy\n",
    "! pip install --user sklearn\n",
    "! pip install --user matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Understanding Linear Regression\n",
    "\n",
    "Linear regression is a statistical technique that produces a linear equation that best models a set of data. When analysts use linear regression to create an equation that predicts one variable, such as relating a customer’s age to sales, the process is called simple regression. In contrast, when more than one predictor variable is used, such as age and gender to predict salary, the process is called multiple regression.\n",
    "\n",
    "The following Python script, SimpleLR.py, uses the linear_model library's LinearRegression function to perform a simple (one predictor value) linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 1\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[0],[1],[2],[3]])  \n",
    "y = np.array([2,3,4,5])\n",
    "\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X, y)\n",
    "print ('Coefficient: ', clf.coef_)\n",
    "print('Y intercept: ', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "The following Python script, PlotLR.py, uses the LinearRegression function to determine the line that best represents the data, and then plots the data and line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 2\n",
    "######################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[0],[1],[2],[3],[4],[5],[6],[7]])  \n",
    "y = np.array([1,3,9,10,27,84,105,169])\n",
    "\n",
    "plt.scatter(X,y)\n",
    "\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X, y)\n",
    "predictions = np.dot(X, clf.coef_)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    " predictions[index] = predictions[index] + clf.intercept_\n",
    "\n",
    "plt.plot(X, predictions)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Looking at a Real-World Example of Simple Linear Regression\n",
    "\n",
    "The University of California Irvine (UCI) dataset repository provides the Auto-MPG dataset which contains average miles-per-gallon (MPG), horse power, weight, number of cylinders, and so on, for many different car types. The following Python script, WeightMPG.py, uses the dataset to create an equation that models the relationship between automobile weight and miles per gallon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "X = data[['weight']].values\n",
    "y = data['mpg']\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "clf = model.fit(X, y)\n",
    "print ('Coefficient: ', clf.coef_)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index], 'Weight: ', X[index,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "When you must predict values based on two or more predictor variables, you can perform multiple linear regression. \n",
    "\n",
    "The following, Python script, MultipleLR.py, uses multiple regression to determine the coeffients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[0, 6, 11],[2, 7, 12],[3, 8, 13],[4, 9, 14],[5, 10, 15]])  \n",
    "y = np.array([46,52,58,64,70])\n",
    "\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X, y)\n",
    "print ('Coefficient: ', clf.coef_)\n",
    "print('Y intercept: ', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "If you multiply the coefficients specified and add the y-intercept, you will find that the results closely approximate the values of Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Looking at a Real-World Multiple Linear Regression\n",
    "\n",
    "Earlier in this notebook you examined the use of Auto-MPG dataset to predict the miles-per-gallon based on the weight of a car. The following Python script, AutoMPGMR.py extends the previous script to use multiple predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "X = data[['weight', 'horsepower', 'cylinders', 'acceleration', 'displacement', 'model year', 'origin']].values\n",
    "y = data['mpg']\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "clf = model.fit(X, y)\n",
    "print ('Coefficient: ', clf.coef_)\n",
    "\n",
    "y2 = model.predict(X)\n",
    "for index in range(len(y2)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', y2[index], 'Weight: ', X[index,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Seattle (King County, Washington) is home to many successful high-tech companies (along with waterfront property) that reflect in the prices of its housing. A popular dataset used for evaluating simple regression models is the House Sales in King County, USA dataset, which contains 19 house attributes and prices for what each house sold.\n",
    "\n",
    "The following Python script, SeattleHousing.py, uses several of the attributes from King County dataset to generate an equation with which you can predict a house price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 3\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('Seattle.csv')\n",
    "\n",
    "# specify attributes(X) to be used for prediction of price(y)\n",
    "X = data[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']].values\n",
    "y = data['price']\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "clf = model.fit(X, y)\n",
    "print ('Coefficient: ', clf.coef_)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Decision Tree Regression\n",
    "\n",
    "A decision tree is a graph-based data structure that a program can use to follow a series of decision paths to arrive at a destination.   \n",
    "You may know that decision trees are used in data classification, by creating a similar structure with decision points that are based upon the different dataset attributes. However, you can also use decision trees to perform decision-tree regression in order to predict continuous data. \n",
    "\n",
    "The following Python script, SimpleDecisionTreeRegression.py, uses the dataset used at the beginning of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "X = np.array([[0],[1],[2],[3]])  \n",
    "y = np.array([2,3,4,5])\n",
    "\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(model.feature_importances_)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "The following Python script, SeattleDT.py, uses decision-tree regression to create an equation you can use to predict housing values in Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 4\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "data = pd.read_csv('Seattle.csv')\n",
    "\n",
    "X = data[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']].values\n",
    "y = data['price']\n",
    "\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(model.feature_importances_)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], '   Predicted: ', predictions[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "Sometimes a decision tree may not be optimal for the dataset. When the decision tree becomes very deep (many levels of nodes) it will often overfill and have a large variance. \n",
    "\n",
    "A random-forest algorithm will create many decision trees and then apply the one that best represents the average of the rest. The following Python script, AutoMPGRF.py, uses random-forest regression to produce coefficients for multiple predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 5\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "X = data[['weight', 'horsepower', 'cylinders', 'acceleration', 'displacement','model year', 'origin']].values\n",
    "y = data['mpg']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(model.feature_importances_)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index], '\\t\\tWeight: ', X[index,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "The following Python script, RandomForestSeattle.py, uses random-forest regression to produce an equation you can use to predict house values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 6\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data = pd.read_csv('Seattle.csv')\n",
    "\n",
    "X = data[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']].values\n",
    "y = data['price']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(model.feature_importances_)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], '  Predicted: ', predictions[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regression\n",
    "\n",
    "The KNN’s classification algorithm is based on the premise “If it walks like duck and quacks like a duck, it’s a duck.” To use KNN, you provide a value for the number K that specifies the number of neighboring dataset values to which a value must be similar in order to be considered part of a group. In short, the K-nearest-neighbor algorithm groups data that are similar to that around it. However, the K-nearest-neighbors can also be used for regression. To predict values, algorithm matches values to its nearest neighbors and then calculates an average.\n",
    "\n",
    "\n",
    "The following Python script, KNNRegression.py, uses the Auto-MPG dataset to predict MPG based on a number of car attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 7\n",
    "######################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "X = data[['weight', 'horsepower', 'cylinders', 'acceleration', 'displacement','model year', 'origin']].values\n",
    "y = data['mpg']\n",
    "\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors = 5)\n",
    "\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X) \n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index], '\\t\\tWeight: ', X[index,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Polynomial Regression\n",
    "\n",
    "As you have learned, a line is not often a perfect fit for the underlying data. In such cases, you may find that a curved line better matches the data. The following Python script, SimplePoly.py, uses the data to perform polynomial regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Chapter 12 (Python) / Deliverable 8\n",
    "######################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([[0],[1],[2],[3],[4],[5],[6],[7]])\n",
    "y = np.array([2,3,9,12,15,18,19,20])\n",
    "\n",
    "plt.scatter(X,y)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "predictions = model.predict(X_poly)\n",
    "\n",
    "plt.plot(X, predictions)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "And finally, the following Python script, SeattlePoly.py, uses polynomial regression to predict Seattle-housing prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data = pd.read_csv('Seattle.csv')\n",
    "\n",
    "X = data[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']].values\n",
    "y = data['price']\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "predictions = model.predict(X_poly)\n",
    "\n",
    "for index in range(len(predictions)):\n",
    "  print('Actual: ', y[index], 'Predicted: ', predictions[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
