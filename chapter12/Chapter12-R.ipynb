{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Chapter 12: Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Data mining is the process of analyzing data to discover patterns and relationships. If you are working with sales data, for example, it makes sense that you would analyze data to determine facts such as:\n",
    "\n",
    "    •\tWhich customer purchased the most products?\n",
    "    •\tWhich customer purchased the least?\n",
    "    •\tWhat was the average sales per customer order?\n",
    "    •\tWhat was the average number of days between orders?\n",
    "    •\tWhat customers have not yet ordered the new product?\n",
    "    •\tAnd so on.\n",
    "\n",
    "Using data in this way to describe past events is descriptive analytics. As you might imagine, being able to analyze data to determine such historical facts is very important and very valuable to businesses. To perform descriptive analytics, you can use statistical tools to generate metrics, you can use visualization tools to chart data, you can use clustering to group data, and more.\n",
    "\n",
    "This notebook, however, is about using data to predict future events—predictive analytics. Companies today use predictive analytics for a wide range of applications:\n",
    "\n",
    "    •\tEstimate the revenue opportunity associated with an upcoming product sale.\n",
    "    •\tPredict the length of time machines will run without failing.\n",
    "    •\tDetermine the loan amount to offer a customer.\n",
    "    •\tWhich customers are likely to become long-term customers?\n",
    "    •\tFor what price will a seaside home in Seattle sell?\n",
    "    •\tAnd more.\n",
    "\n",
    "Using supervised learning (training with labelled datasets to learn links between inputs and outputs), you can predict in which class (category) an object should reside given predictor variables. Classification works with discrete categories, meaning data that has finite values, such as the type of a car, breed of a dog, color of hair, number of students (you can’t have a fractional student), and so on. In contrast, continuous values have an infinite set of values, such as a company’s projected revenue, the average basketball player’s height, and the range of temperatures in Phoenix.  \n",
    "\n",
    "This notebook focuses on predicting continuous values using a technique called regression, the goal of which is to produce an equation which you can then use to predict results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Some of the scripts presented in this notebook use R libraries (known as packages) which have been pre-installed for you. If you had been required to install these libaries on your own, you would issue the commands below.\n",
    "```R\n",
    "install.packages(\"FNN\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Understanding Linear Regression\n",
    "\n",
    "Linear regression is a statistical technique that produces a linear equation that best models a set of data. When analysts use linear regression to create an equation that predicts one variable, such as relating a customer’s age to sales, the process is called simple regression. In contrast, when more than one predictor variable is used, such as age and gender to predict salary, the process is called multiple regression.\n",
    "\n",
    "The following R script, SimpleLR.R, uses the linear_model library LinearRegression function to perform a simple (one predictor value) linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Chapter 12 (R) / Deliverable 1\n",
    "#################################\n",
    "\n",
    "df <- data.frame(\n",
    "      x = c(0,1,2,3),\n",
    "      y = c(2,3,4,5))\n",
    "\n",
    "lm(formula = y ~ x, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at a Real-World Example of Simple Linear Regression\n",
    "\n",
    "The University of California Irvine (UCI) dataset repository provides the Auto-MPG dataset which contains average miles-per-gallon (MPG), horse power, weight, number of cylinders, and so on, for many different car types.\n",
    "\n",
    "The following R script, WeightMPG.R, uses the dataset to create an equation that models the relationship between automobile weight and miles per gallon. We specify the relationship to model in the linear_model(lm) function, where the variable on the left side of the tilde(~) operator is the dependent variable, and one on the right is the independent variable. We also specify our dataframe as the data to be used, and store this relationship in the \"model\" variable. Now that we have a model, which answers the question \"how does mpg depend on weight,\" we can employ it to predict mpg values, and finally, compare it with the actual value of mpg to gauge its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Chapter 12 (R) / Deliverable 2\n",
    "#################################\n",
    "\n",
    "df <- read.csv(file='auto-mpg.csv')\n",
    "\n",
    "model <- lm(formula = mpg ~ weight, data=df)\n",
    "\n",
    "prediction <- predict(model,df)\n",
    "\n",
    "print (cbind(df$mpg, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "When you must predict values based on two or more predictor variables, you can perform multiple linear regression. \n",
    "\n",
    "The following, R script, MultipleLR.R, uses multiple regression to determine the coeffiences that best estimate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(\n",
    "      y = c(46, 52, 58, 64, 70),\n",
    "      x0 = c(0, 2, 3, 4, 5), \n",
    "      x1 = c(6, 7, 8, 9, 10),\n",
    "      x2 = c(11, 12, 13, 14, 15))\n",
    "\n",
    "print(lm(y~x0+x1+x2, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "If you multiply the coefficients specified and add the y-intercept, you will find that the results closely approximate the values of Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at a Real-World Multiple Linear Regression\n",
    "\n",
    "Earlier in this notebook you examined the use of Auto-MPG dataset to predict the miles-per-gallon based on the weight of a car. The following R script, AutoMPGMR.R extends the previous script to use multiple predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df <- read.csv(file='auto-mpg.csv')\n",
    "df = df[-8] # drop car name\n",
    "\n",
    "model <- lm(formula = mpg ~ ., data=df)\n",
    "\n",
    "prediction <- predict(model, df[, 2:8])\n",
    "actual <- df[,1:1]\n",
    "print(cbind(actual, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seattle (King County, Washington) is home to many successful high-tech companies (along with waterfront property) that reflect in the prices of its housing. A popular dataset used for evaluating simple regression models is the House Sales in King County, USA dataset, which contains 19 house attributes and prices for what each house sold.\n",
    "\n",
    "The following R script, SeattleHousing.R, uses 10 of the attributes from the King County dataset to generate an equation with which you can predict a house price. The linear model function is again used, this time specifying price as the dependent variable. For the independent variables, we specify all attributes read into our dataframe (indicated by the period following the tilde). In our prediction statement, we invoke our model to perform the prediction, and specify the full range of attributes in our dataframe, except for the first since it is the independent variable we are predicting (price):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Chapter 12 (R) / Deliverable 3\n",
    "#################################\n",
    "\n",
    "df <- read.csv(file='seattle.csv')\n",
    "\n",
    "df <- df[1:13] # read range of attributes into dataframe\n",
    "df <- df[-2] # drop date\n",
    "df <- df[-1] # drop id\n",
    "\n",
    "model <- lm(formula = price ~., data=df)\n",
    "\n",
    "prediction <- predict(model, df[,2:11])\n",
    "actual <- df[,1:1]\n",
    "print(cbind(actual, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Decision Tree Regression\n",
    "\n",
    "A decision tree is a graph-based data structure that a program can use to follow a series of decision paths to arrive at a destination.\n",
    "You may know that decision trees are used in data classification, by creating a similar structure with decision points that are based upon the different dataset attributes. However, you can also use decision trees to perform decision-tree regression to predict continuous data. \n",
    "\n",
    "\n",
    "The following R script, SeattleDT.R, uses decision-tree regression to create an equation you can use to predict housing values in Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "df <- read.csv(file='seattle.csv')\n",
    "\n",
    "df <- df[1:13]\n",
    "df <- df[-2] # drop date\n",
    "df <- df[-1] # drop id\n",
    "\n",
    "model <- rpart(price~., data=df)\n",
    "\n",
    "prediction <- predict(model, df[,2:11])\n",
    "actual <- df[,1:1]\n",
    "print(cbind(actual, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# K-Nearest Neighbors Regression\n",
    "\n",
    "The KNN’s classification algorithm is based on the premise “If it walks like duck and quacks like a duck, it’s a duck.” To use KNN, you provide a value for the number K that specifies the number of neighboring data-set values to which a value must  be similar in order to be considered part of a group. In short, the K-nearest-neighbor algorithm groups data that are similar to that around it. However, the K-nearest-neighbors can also be used for regression. To predict values, algorithm matches values to its nearest neighbors and then calculates an average.\n",
    "\n",
    "The following R script, KNNRegression.R, uses the Auto-MPG dataset to predict MPG based on a car’s weight. As you can see, 70 percent of the data is assigned to the training set (the portion of data used to learn input/output links):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Chapter 12 (R) / Deliverable 4\n",
    "#################################\n",
    "\n",
    "library(FNN)\n",
    "\n",
    "df <- read.csv(file='auto-mpg.csv')\n",
    "\n",
    "## Split in train + test set. Assigns 70 percent of data to train set, and remainder goes to the test set.\n",
    "indexes <- sample(1:nrow(df),as.integer(0.7*nrow(df)))\n",
    "\n",
    "trainData <- df[indexes,1:7]\n",
    "testData <- df[-indexes,1:7]\n",
    "\n",
    "## A 3-nearest neighbors model \n",
    "model <- knn.reg(train = trainData, test = testData, y = trainData$mpg, k=3)\n",
    "prediction <- model$pred\n",
    "\n",
    "actual <- testData[,1:1]\n",
    "print(cbind(actual, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
